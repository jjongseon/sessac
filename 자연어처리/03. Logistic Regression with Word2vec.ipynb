{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_IN_PATH +TRAIN_CLEAN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for review in reviews:\n",
    "    sentences.append(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300  # 단어에 대해 임베딩된 벡터의 차원\n",
    "min_word_count = 40 # 적은 빈도수 배제\n",
    "num_workers = 4     # 학습을 위한 프로세스 개수 지정\n",
    "context = 10        # 컨텍스트 윈도우 크기 지정\n",
    "downsampling = 1e-3 # 빠른 학습을 위해 정답 단어 레이블에 대한 다운샘플링\n",
    "                    # 비율지정(보통 0.001이 좋은 성능을 낸다고 함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# level = logging.INFO : word2vec의 학습과정에서 로그메시지를 양식에맞게 -\n",
    "# - info 수준으로 보여줌\n",
    "logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s',level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 17:17:29,354:INFO:collecting all words and their counts\n",
      "2022-11-07 17:17:29,355:INFO:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-11-07 17:17:29,584:INFO:PROGRESS: at sentence #10000, processed 1205223 words, keeping 51374 word types\n",
      "2022-11-07 17:17:29,831:INFO:PROGRESS: at sentence #20000, processed 2396605 words, keeping 67660 word types\n",
      "2022-11-07 17:17:29,955:INFO:collected 74065 word types from a corpus of 2988089 raw words and 25000 sentences\n",
      "2022-11-07 17:17:29,955:INFO:Creating a fresh vocabulary\n",
      "2022-11-07 17:17:30,016:INFO:Word2Vec lifecycle event {'msg': 'effective_min_count=40 retains 8160 unique words (11.02% of original 74065, drops 65905)', 'datetime': '2022-11-07T17:17:30.016690', 'gensim': '4.2.0', 'python': '3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-07 17:17:30,017:INFO:Word2Vec lifecycle event {'msg': 'effective_min_count=40 leaves 2627273 word corpus (87.92% of original 2988089, drops 360816)', 'datetime': '2022-11-07T17:17:30.017678', 'gensim': '4.2.0', 'python': '3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-07 17:17:30,066:INFO:deleting the raw counts dictionary of 74065 items\n",
      "2022-11-07 17:17:30,070:INFO:sample=0.001 downsamples 30 most-common words\n",
      "2022-11-07 17:17:30,071:INFO:Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2494384.49928802 word corpus (94.9%% of prior 2627273)', 'datetime': '2022-11-07T17:17:30.071686', 'gensim': '4.2.0', 'python': '3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'prepare_vocab'}\n",
      "2022-11-07 17:17:30,138:INFO:estimated required memory for 8160 words and 300 dimensions: 23664000 bytes\n",
      "2022-11-07 17:17:30,139:INFO:resetting layer weights\n",
      "2022-11-07 17:17:30,149:INFO:Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-11-07T17:17:30.149720', 'gensim': '4.2.0', 'python': '3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'build_vocab'}\n",
      "2022-11-07 17:17:30,151:INFO:Word2Vec lifecycle event {'msg': 'training model with 4 workers on 8160 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2022-11-07T17:17:30.151721', 'gensim': '4.2.0', 'python': '3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-11-07 17:17:31,156:INFO:EPOCH 0 - PROGRESS: at 50.00% examples, 1257361 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 17:17:32,129:INFO:EPOCH 0: training on 2988089 raw words (2494564 effective words) took 2.0s, 1263993 effective words/s\n",
      "2022-11-07 17:17:33,137:INFO:EPOCH 1 - PROGRESS: at 49.68% examples, 1244230 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 17:17:34,124:INFO:EPOCH 1: training on 2988089 raw words (2494067 effective words) took 2.0s, 1252761 effective words/s\n",
      "2022-11-07 17:17:35,139:INFO:EPOCH 2 - PROGRESS: at 48.08% examples, 1194334 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 17:17:36,141:INFO:EPOCH 2 - PROGRESS: at 96.07% examples, 1192170 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 17:17:36,220:INFO:EPOCH 2: training on 2988089 raw words (2494103 effective words) took 2.1s, 1192168 effective words/s\n",
      "2022-11-07 17:17:37,225:INFO:EPOCH 3 - PROGRESS: at 42.16% examples, 1058019 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 17:17:38,227:INFO:EPOCH 3 - PROGRESS: at 90.03% examples, 1124444 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 17:17:38,412:INFO:EPOCH 3: training on 2988089 raw words (2494316 effective words) took 2.2s, 1140052 effective words/s\n",
      "2022-11-07 17:17:39,417:INFO:EPOCH 4 - PROGRESS: at 49.68% examples, 1248825 words/s, in_qsize 7, out_qsize 0\n",
      "2022-11-07 17:17:40,375:INFO:EPOCH 4: training on 2988089 raw words (2494357 effective words) took 2.0s, 1273837 effective words/s\n",
      "2022-11-07 17:17:40,376:INFO:Word2Vec lifecycle event {'msg': 'training on 14940445 raw words (12471407 effective words) took 10.2s, 1219852 effective words/s', 'datetime': '2022-11-07T17:17:40.376351', 'gensim': '4.2.0', 'python': '3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'train'}\n",
      "2022-11-07 17:17:40,376:INFO:Word2Vec lifecycle event {'params': 'Word2Vec<vocab=8160, vector_size=300, alpha=0.025>', 'datetime': '2022-11-07T17:17:40.376351', 'gensim': '4.2.0', 'python': '3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19044-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, workers=num_workers, vector_size=num_features, min_count=min_word_count,\n",
    "                        window=context,sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "words : 단어의 모음인 하나의 리뷰\n",
    "model : word2vec모델\n",
    "num_features : word2vec로 임베딩할 때 정했던 벡터의 차원 수\n",
    "'''\n",
    "def get_features(words, model, num_features):\n",
    "    # 출력 벡터 초기화\n",
    "    feature_vector = np.zeros((num_features),dtype=np.float32)\n",
    "    num_words = 0\n",
    "    # 어휘 사전 준비\n",
    "    index_to_key_set = set(model.wv.index_to_key)\n",
    "    for w in words:\n",
    "        if w in index_to_key_set:\n",
    "            num_words += 1\n",
    "            # 사전에 해당하는 단어에 대해 단어 벡터를 더함\n",
    "            feature_vector = np.add(feature_vector, model.wv[w])\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(reviews,model,num_features):\n",
    "    dataset=list()\n",
    "    \n",
    "    for s in reviews:\n",
    "        dataset.append(get_features(s,model,num_features))\n",
    "    \n",
    "    reviewFeatureVecs=np.stack(dataset)\n",
    "\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_vecs = get_dataset(sentences,model,num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X = test_data_vecs\n",
    "y = np.array(sentiments)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "                            test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seon\\.conda\\envs\\study\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)\n",
    "predicted = lgs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.866000\n",
      "Precision: 0.859868\n",
      "Recall: 0.876935\n",
      "F1-Score: 0.868318\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy: %f\" % lgs.score(X_test, y_test))  #checking the accuracy\n",
    "print(\"Precision: %f\" % metrics.precision_score(y_test, predicted))\n",
    "print(\"Recall: %f\" % metrics.recall_score(y_test, predicted))\n",
    "print(\"F1-Score: %f\" % metrics.f1_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1e21767e69694e6271cff48837b0419ac731655a1ddac958206c0399c4912a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
